{
 "cells": [
  {
   "cell_type": "raw",
   "id": "7049c3a3",
   "metadata": {},
   "source": [
    "There are basically 2 main areas we should focus on for optimization..\n",
    "1. cluster configuration level - resource level optimization \n",
    "2. Application code level - how we write the code.Partitioning, bucketing, \n",
    "cache & persist, avoid/minimize shuffling of data, join optimizations,using \n",
    "optimized file formats, using reduceByKey instead of groupByKey\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "adfa3523",
   "metadata": {},
   "source": [
    "resources - memory (RAM) , CPU cores (Compute) \n",
    "our intention is to make sure our job should get the right amount of resources.\n",
    "10 Node cluster (10 worker nodes)\n",
    "16 cpu cores64 GB RAM Executor (it is like a container of resources)\n",
    "1 node can hold more than one executor in a single worker node we can have multiple executors (multiple containers) \n",
    "container - cpu cores + memory (RAM) \n",
    "executor/container/JVM\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "38f4c17a",
   "metadata": {},
   "source": [
    "16 cores , 64 gb ram1\n",
    "here are 2 strategies when creating containers.\n",
    "1. Thin executor - intention is to create more executors with each executor holding minimumpossible resources. \n",
    "total of 16 executors , with each executor holdingeach executor - 1 core, 4 gb ramDrawback ==========\n",
    "1. In this scenario we will be losing the benefits of multithreading. \n",
    "2. A lot of copies of broadcast variable are required..each executor should receive its own copy."
   ]
  },
  {
   "cell_type": "raw",
   "id": "49d34f62",
   "metadata": {},
   "source": [
    "# 2. Fat executor - intention is to give maximum resources to each executor.\n",
    "16 cores, 64 gb ram you can create a executor which can hold 16 cpu cores and 64 gb ram.. \n",
    "Drawbacks ==========\n",
    "1. It is obverved that if the executor holds more than 5 cpu cores then the hdfs throughputsuffers.\n",
    "2. if the executor holds very huge amount of memory, then the garbage collection takes a lot of time.\n",
    "garbage collection means removing unused objects from memory.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "465a713a",
   "metadata": {},
   "source": [
    "10 Nodes \n",
    "16 cores\n",
    "64 GB Ram\n",
    "1.Tiny executors 2. Fat executors\n",
    "\n",
    "16 cores , 64 GB Ram\n",
    "\n",
    "1 core is given for other background activities\n",
    "1 gb RAM is given for operating system in each node \n",
    "\n",
    "we are now left with 15 cores, 63 GB Ram\n",
    "=> we want multithreading within a executor (> 1 cpu core per executor) \n",
    "=> we do not want our hdfs throughput to suffer (it suffers when we use more that 5 cores perexecutor) \n",
    "5 is the right choice of number of cpu cores in each executor.\n",
    "\n",
    "15 cores, 63 GB Ram - each machinewe can have 3 executors running on each worker nodeeach executor will contain 5 cpu cores and 21 GB Ram.\n",
    "\n",
    "out of this 21 GB RAM some of it will go as part of overhead (off heap memory)\n",
    "\n",
    "max (384MB , 7% of executor memory) \n",
    "= 1.5 GB (overhead / off heap memory) - this is not part of containers.\n",
    "\n",
    "21 - 1.5 = ~19 GB\n",
    "that mean in each worker node we have 3 executors.\n",
    "\n",
    "each executor holds - 5 cpu cores, 19 GB RAM \n",
    "we have a 10 node cluster/ worker nodes\n",
    "10 * 3 = 30 (executors across the cluster)\n",
    "30 executors with each executor holding -\n",
    "5 cpu cores, 19 GB RAM3\n",
    "1 executor out of these 30 will be given for YARN Application Manager\n",
    "30 - 1 = 29 executors"
   ]
  },
  {
   "cell_type": "raw",
   "id": "53f2d22d",
   "metadata": {},
   "source": [
    "5 worker nodes\n",
    "8 cpu cores , 32 GB RAM\n",
    "out of 32 GB usable is 24 GB \n",
    "\n",
    "for yarn containersexecutor/container - \n",
    "should have memory in between 1 & 4 GB\n",
    "in each worker node there are 8 physical cpu cores..\n",
    "\n",
    "we get 16 VCPU's\n",
    "out of 32 GB usable is 24 GB for yarn containers\n",
    "out of 16 we can use 12 cores for yarn containers\n",
    "24 GB RAM , 12 VCPU's on each worker node \n",
    "5 such worker nodes..\n",
    "\n",
    "executor memory - 1 to 4 GB\n",
    "executor cores - 1 or 2 \n",
    "\n",
    "maximum executors you can create in entire cluster. \n",
    "\n",
    "12 executors in each worker node \n",
    "12 * 5 = 60 executors/containers\n",
    "\n",
    "60 executors with each holding 1 cpu cores 2 GB Ram\n",
    "30 executors with each holding 2 cpu cores 4 GB Ram\n",
    "\n",
    "5 worker nodes 24 GB usable Ram\n",
    "12 VCPU's \n",
    "in our resource pool which YARN is managing we have\n",
    "\n",
    "120 GB RAM and 60 CPU Cores.\n",
    "24 * 5 = 120 GB RAM \n",
    "12 * 5 = 60 cpu cores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9d6a6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
