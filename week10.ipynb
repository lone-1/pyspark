{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8eb8a672",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1627123b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a288f731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/26 18:59:39 WARN Utils: Your hostname, ashwins-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 192.168.29.199 instead (on interface en0)\n",
      "22/10/26 18:59:39 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/26 18:59:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark=SparkSession.builder\\\n",
    "                  .master(\"local\")\\\n",
    "                  .appName('new')\\\n",
    "                  .getOrCreate()\n",
    "sc=spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "362c099e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('data', 16394.640000000003)\n",
      "('big', 12889.28000000001)\n",
      "('in', 5774.839999999997)\n",
      "('hadoop', 4818.339999999999)\n",
      "('course', 4191.59)\n",
      "('training', 4099.369999999998)\n",
      "('online', 3484.4199999999983)\n",
      "('courses', 2565.7799999999993)\n",
      "('intellipaat', 2081.2200000000003)\n",
      "('analytics', 1458.5100000000004)\n",
      "('tutorial', 1383.3700000000001)\n",
      "('hyderabad', 1118.16)\n",
      "('spark', 1078.72)\n",
      "('best', 1047.7)\n",
      "('bangalore', 1039.27)\n",
      "('and', 985.7999999999998)\n",
      "('certification', 967.4400000000002)\n",
      "('for', 967.0500000000001)\n",
      "('of', 871.4200000000001)\n",
      "('to', 848.33)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "initial_rdd = sc.textFile(\"bigdatacampaigndata-201014-183159.csv\")\n",
    "mapped_input = initial_rdd.map(lambda x: (float(x.split(\",\")[10]),x.split(\",\")[0]))\n",
    "words = mapped_input.flatMapValues(lambda x: x.split(\" \"))\n",
    "final_mapped = words.map(lambda x: (x[1].lower(),x[0]))\n",
    "total = final_mapped.reduceByKey(lambda x,y: x+y)\n",
    "sorted = total.sortBy(lambda x: x[1],False)\n",
    "result = sorted.take(20)\n",
    "for x in result:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f486d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans=sorted.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b75fe8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('data', 16394.640000000003)\n",
      "('big', 12889.28000000001)\n",
      "('in', 5774.839999999997)\n",
      "('hadoop', 4818.339999999999)\n",
      "('course', 4191.59)\n",
      "('training', 4099.369999999998)\n",
      "('online', 3484.4199999999983)\n",
      "('courses', 2565.7799999999993)\n",
      "('intellipaat', 2081.2200000000003)\n",
      "('analytics', 1458.5100000000004)\n",
      "('tutorial', 1383.3700000000001)\n",
      "('hyderabad', 1118.16)\n",
      "('spark', 1078.72)\n",
      "('best', 1047.7)\n",
      "('bangalore', 1039.27)\n",
      "('and', 985.7999999999998)\n",
      "('certification', 967.4400000000002)\n",
      "('for', 967.0500000000001)\n",
      "('of', 871.4200000000001)\n",
      "('to', 848.33)\n",
      "('with', 728.3000000000001)\n",
      "('cloudxlab', 707.52)\n",
      "('bigdata', 694.4800000000001)\n",
      "('dataflair', 643.9)\n",
      "('chennai', 604.0400000000001)\n",
      "('on', 573.41)\n",
      "('institute', 531.2099999999999)\n",
      "('learn', 530.3800000000001)\n",
      "('analysis', 487.80000000000007)\n",
      "('india', 471.83000000000004)\n",
      "('engineer', 457.09)\n",
      "('institutes', 437.13999999999993)\n",
      "('apache', 422.94000000000005)\n",
      "('placement', 413.51)\n",
      "('the', 395.62999999999994)\n",
      "('is', 394.02)\n",
      "('learning', 384.4)\n",
      "('fees', 382.5)\n",
      "('classes', 373.69000000000005)\n",
      "('delhi', 358.72)\n",
      "('edureka', 351.44)\n",
      "('analyst', 340.40999999999997)\n",
      "('engineering', 318.22)\n",
      "('iit', 308.72999999999996)\n",
      "('coursera', 293.25)\n",
      "('python', 287.03)\n",
      "('pune', 284.71)\n",
      "('curso', 277.53000000000003)\n",
      "('which', 263.08000000000004)\n",
      "('reviews', 258.32)\n",
      "('cloudera', 258.06)\n",
      "('a', 254.42000000000002)\n",
      "('simplilearn', 252.45)\n",
      "('com', 251.33)\n",
      "('scala', 250.73)\n",
      "('program', 245.53)\n",
      "('de', 245.31)\n",
      "('master', 241.55)\n",
      "('gratis', 240.72000000000003)\n",
      "('coaching', 238.98000000000002)\n",
      "('by', 232.32)\n",
      "('science', 228.32999999999998)\n",
      "('fee', 226.39000000000001)\n",
      "('class', 221.82999999999998)\n",
      "('top', 220.06)\n",
      "('architect', 210.7)\n",
      "('scientist', 192.68)\n",
      "('review', 191.82)\n",
      "('pg', 190.9)\n",
      "('study', 188.29)\n",
      "('ameerpet', 184.94000000000003)\n",
      "('cost', 182.9)\n",
      "('from', 180.45)\n",
      "('content', 172.45)\n",
      "('masters', 163.98999999999998)\n",
      "('line', 159.58)\n",
      "('beginners', 159.15)\n",
      "('near', 158.2)\n",
      "('full', 157.97)\n",
      "('flair', 154.13)\n",
      "('acadgild', 153.39000000000001)\n",
      "('me', 150.60999999999999)\n",
      "('microsoft', 148.73)\n",
      "('5', 147.97)\n",
      "('diploma', 147.76000000000002)\n",
      "('academy', 147.18)\n",
      "('2020', 145.46)\n",
      "('developer', 137.66)\n",
      "('lab', 135.57999999999998)\n",
      "('en', 135.04999999999998)\n",
      "('computing', 132.16)\n",
      "('cloud', 130.36)\n",
      "('software', 129.96)\n",
      "('certified', 128.48000000000002)\n",
      "('university', 127.91)\n",
      "('www', 125.23)\n",
      "('details', 124.53999999999999)\n",
      "('1', 122.72000000000001)\n",
      "('java', 122.52000000000001)\n",
      "('certificate', 120.71)\n",
      "('sql', 120.16)\n",
      "('projects', 116.88999999999999)\n",
      "('udemy', 115.14)\n",
      "('technology', 114.56)\n",
      "('cours', 114.36000000000001)\n",
      "('syllabus', 112.43)\n",
      "('ibm', 111.97999999999999)\n",
      "('career', 107.28999999999999)\n",
      "('jigsaw', 104.06)\n",
      "('2', 102.28999999999999)\n",
      "('cluster', 101.47999999999999)\n",
      "('an', 101.28999999999999)\n",
      "('msc', 98.74)\n",
      "('do', 98.66)\n",
      "('programs', 97.96)\n",
      "('gratuito', 95.64)\n",
      "('colleges', 95.60000000000001)\n",
      "('school', 94.49000000000001)\n",
      "('large', 94.41)\n",
      "('universities', 94.32000000000001)\n",
      "('professional', 93.71000000000001)\n",
      "('eligibility', 93.67)\n",
      "('what', 93.58)\n",
      "('fundamentals', 93.35)\n",
      "('kubernetes', 91.92999999999999)\n",
      "('kolkata', 91.74000000000001)\n",
      "('marketing', 91.00999999999999)\n",
      "('types', 90.53999999999999)\n",
      "('centre', 90.47999999999999)\n",
      "('overview', 88.68)\n",
      "('complete', 85.13999999999999)\n",
      "('database', 85.1)\n",
      "('introduction', 84.75999999999999)\n",
      "('good', 83.86)\n",
      "('roorkee', 83.41999999999999)\n",
      "('time', 83.36)\n",
      "('world', 83.00999999999999)\n",
      "('bits', 81.82)\n",
      "('pilani', 81.82)\n",
      "('foundation', 81.73)\n",
      "('ourse', 78.94)\n",
      "('genomic', 78.94)\n",
      "('selection', 78.94)\n",
      "('mining', 78.66)\n",
      "('using', 77.32000000000001)\n",
      "('inceptez', 77.3)\n",
      "('management', 77.22999999999999)\n",
      "('scratch', 77.11000000000001)\n",
      "('it', 76.28)\n",
      "('tools', 74.88)\n",
      "('mba', 74.84)\n",
      "('i', 74.68)\n",
      "('les', 74.56)\n",
      "('3', 73.53)\n",
      "('job', 71.77000000000001)\n",
      "('international', 70.2)\n",
      "('trainer', 69.82)\n",
      "('conitive', 69.8)\n",
      "('solution', 69.77)\n",
      "('udacity', 69.73)\n",
      "('questions', 69.24000000000001)\n",
      "('technologies', 69.05000000000001)\n",
      "('college', 68.73)\n",
      "('end', 68.54)\n",
      "('sri', 67.65)\n",
      "('lanka', 67.65)\n",
      "('intelipatt', 67.12)\n",
      "('trainin', 67.12)\n",
      "('project', 66.01)\n",
      "('basics', 65.24)\n",
      "('great', 65.0)\n",
      "('uk', 64.99000000000001)\n",
      "('10', 64.94999999999999)\n",
      "('docker', 64.94)\n",
      "('ivy', 64.72)\n",
      "('pro', 64.72)\n",
      "('b', 64.25)\n",
      "('specialization', 64.09)\n",
      "('bigdataphysicsclasses', 63.29)\n",
      "('cca', 62.61)\n",
      "('175', 62.61)\n",
      "('real', 62.47)\n",
      "('center', 62.45)\n",
      "('quiz', 61.92999999999999)\n",
      "('comment', 61.25)\n",
      "('20', 60.56)\n",
      "('use', 59.980000000000004)\n",
      "('access', 59.94)\n",
      "('canada', 59.78)\n",
      "('storahe', 59.78)\n",
      "('related', 59.69)\n",
      "('acadamy', 59.64)\n",
      "('thiruvanthapuram', 59.64)\n",
      "('p', 59.56)\n",
      "('programme', 59.48)\n",
      "('required', 59.26)\n",
      "('ipc', 59.2)\n",
      "('power', 59.14)\n",
      "('cursos', 58.989999999999995)\n",
      "('distance', 58.85)\n",
      "('https', 58.79)\n",
      "('avaliação', 58.74)\n",
      "('aol', 58.74)\n",
      "('questionário', 58.74)\n",
      "('org', 58.56)\n",
      "('aws', 58.519999999999996)\n",
      "('image', 58.47)\n",
      "('google', 58.31)\n",
      "('iguru', 58.19)\n",
      "('paper', 58.17)\n",
      "('guarantee', 57.540000000000006)\n",
      "('assessment', 57.519999999999996)\n",
      "('101', 57.44)\n",
      "('hindi', 57.15)\n",
      "('pgp', 57.08)\n",
      "('claases', 57.02)\n",
      "('where', 56.49)\n",
      "('books', 56.28)\n",
      "('unacademy', 55.79)\n",
      "('login', 55.68)\n",
      "('intellipat', 54.97)\n",
      "('days', 54.78)\n",
      "('live', 54.59)\n",
      "('when', 54.54)\n",
      "('app', 53.97)\n",
      "('formation', 53.239999999999995)\n",
      "('ligne', 53.239999999999995)\n",
      "('guide', 53.14)\n",
      "('sample', 53.1)\n",
      "('not', 53.08)\n",
      "('providers', 52.89)\n",
      "('jaipur', 52.48)\n",
      "('april', 52.48)\n",
      "('cloudx', 52.34)\n",
      "('kelly', 51.980000000000004)\n",
      "('4', 51.239999999999995)\n",
      "('ke', 50.47)\n",
      "('liye', 50.47)\n",
      "('digital', 50.11)\n",
      "('ragnarok', 49.92)\n",
      "('kursus', 49.87)\n",
      "('hardoop', 49.56)\n",
      "('code', 49.55)\n",
      "('terminal', 49.55)\n",
      "('deta', 49.54)\n",
      "('volume', 49.54)\n",
      "('lakes', 49.47)\n",
      "('lake', 49.41)\n",
      "('following', 49.36)\n",
      "('information', 49.32)\n",
      "('about', 49.32)\n",
      "('databricks', 49.31)\n",
      "('topic', 49.24)\n",
      "('mentors', 49.16)\n",
      "('hive', 49.150000000000006)\n",
      "('text', 49.120000000000005)\n",
      "('architecture', 49.04)\n",
      "('places', 49.02)\n",
      "('coimbatore', 49.02)\n",
      "('go', 48.94)\n",
      "('prwatech', 48.82)\n",
      "('jobs', 48.27)\n",
      "('12', 48.059999999999995)\n",
      "('you', 47.87)\n",
      "('need', 47.87)\n",
      "('import', 47.87)\n",
      "('portion', 47.87)\n",
      "('relational', 47.87)\n",
      "('every', 47.87)\n",
      "('day', 47.87)\n",
      "('as', 47.87)\n",
      "('files', 47.87)\n",
      "('hdfs', 47.87)\n",
      "('generate', 47.87)\n",
      "('interact', 47.87)\n",
      "('your', 47.87)\n",
      "('latest', 47.62)\n",
      "('can', 47.08)\n",
      "('students', 47.050000000000004)\n",
      "('example', 46.97)\n",
      "('structure', 46.870000000000005)\n",
      "('bihar', 46.64)\n",
      "('sharif', 46.64)\n",
      "('queries', 45.730000000000004)\n",
      "('bangladesh', 44.96)\n",
      "('e', 44.9)\n",
      "('tamil', 44.76)\n",
      "('week', 44.68)\n",
      "('last', 44.03)\n",
      "('short', 43.8)\n",
      "('pass', 42.76)\n",
      "('setup', 42.72)\n",
      "('limited', 42.64)\n",
      "('list', 41.63)\n",
      "('btm', 41.61)\n",
      "('layout', 41.61)\n",
      "('offering', 41.52)\n",
      "('genomics', 41.52)\n",
      "('_', 40.64)\n",
      "('scholarship', 40.0)\n",
      "('statistical', 40.0)\n",
      "('cheap', 39.63)\n",
      "('класс', 39.43)\n",
      "('eğitimi', 39.09)\n",
      "('experience', 38.74)\n",
      "('step', 38.24)\n",
      "('ที่ไหน', 38.1)\n",
      "('เปิด', 38.1)\n",
      "('สอน', 38.1)\n",
      "('ฟรี', 38.1)\n",
      "('scale', 37.23)\n",
      "('system', 37.23)\n",
      "('horizontal', 36.61)\n",
      "('opportunities', 35.93)\n",
      "('centres', 35.12)\n",
      "('preparation', 35.0)\n",
      "('mapreduce', 34.99)\n",
      "('application', 34.99)\n",
      "('classpath', 34.99)\n",
      "('case', 34.98)\n",
      "('subject', 34.97)\n",
      "('ca', 34.96)\n",
      "('coursedata', 34.96)\n",
      "('labs', 34.95)\n",
      "('bangkok', 34.95)\n",
      "('pgdm', 34.95)\n",
      "('charging', 34.94)\n",
      "('section', 34.94)\n",
      "('rcm', 34.94)\n",
      "('dlehi', 34.93)\n",
      "('most', 34.92)\n",
      "('institution', 34.92)\n",
      "('strategy', 34.85)\n",
      "('greatlearing', 34.84)\n",
      "('données', 34.84)\n",
      "('regular', 34.84)\n",
      "('hiw', 34.84)\n",
      "('orovide', 34.84)\n",
      "('inspecs', 34.82)\n",
      "('velachery', 34.82)\n",
      "('bigdaa', 34.82)\n",
      "('pipeline', 34.72)\n",
      "('lms', 34.69)\n",
      "('red', 34.68)\n",
      "('hat', 34.68)\n",
      "('title', 34.67)\n",
      "('datatutorial', 34.61)\n",
      "('would', 34.61)\n",
      "('help', 34.61)\n",
      "('lucknow', 34.6)\n",
      "('cognative', 34.59)\n",
      "('europe', 34.59)\n",
      "('bharathiar', 34.58)\n",
      "('kphb', 34.58)\n",
      "('radicaltechnologies', 34.57)\n",
      "('co', 34.57)\n",
      "('could', 34.56)\n",
      "('vancouver', 34.46)\n",
      "('interview', 34.45)\n",
      "('edvancer', 34.35)\n",
      "('minimum', 34.33)\n",
      "('qualifications', 34.33)\n",
      "('nural', 34.22)\n",
      "('network', 34.22)\n",
      "('anlyst', 34.21)\n",
      "('patna', 34.2)\n",
      "('paid', 34.09)\n",
      "('under', 34.09)\n",
      "('3000', 34.09)\n",
      "('acadglid', 34.06)\n",
      "('intoduction', 34.04)\n",
      "('intro', 34.04)\n",
      "('definitive', 34.02)\n",
      "('tranning', 34.02)\n",
      "('there', 34.010000000000005)\n",
      "('expert', 33.8)\n",
      "('costing', 33.76)\n",
      "('select', 33.65)\n",
      "('available', 33.53)\n",
      "('crunching', 33.27)\n",
      "('peer', 33.05)\n",
      "('graded', 33.05)\n",
      "('assignment', 33.05)\n",
      "('pay', 32.89)\n",
      "('after', 32.89)\n",
      "('ivyproschool', 32.35)\n",
      "('data101', 32.29)\n",
      "('light', 32.02)\n",
      "('tutor', 31.88)\n",
      "('benefits', 31.78)\n",
      "('email', 31.77)\n",
      "('trainers', 31.46)\n",
      "('npntraining', 31.4)\n",
      "('broadway', 31.25)\n",
      "('third', 30.49)\n",
      "('all', 30.49)\n",
      "('session', 30.49)\n",
      "('starting', 30.49)\n",
      "('5www', 30.49)\n",
      "('gs', 30.49)\n",
      "('im', 30.49)\n",
      "('n', 30.49)\n",
      "('qjavq5catum', 30.49)\n",
      "('affiliations', 30.0)\n",
      "('edupristine', 30.0)\n",
      "('certificacion', 30.0)\n",
      "('construction', 30.0)\n",
      "('field', 30.0)\n",
      "('axtria', 29.99)\n",
      "('fre', 29.99)\n",
      "('cientista', 29.99)\n",
      "('dados', 29.99)\n",
      "('collect', 29.98)\n",
      "('search', 29.98)\n",
      "('location', 29.98)\n",
      "('offered', 29.98)\n",
      "('engg', 29.98)\n",
      "('omr', 29.98)\n",
      "('qlikview', 29.96)\n",
      "('rahul', 29.95)\n",
      "('khati', 29.95)\n",
      "('ignite', 29.94)\n",
      "('wbt', 29.86)\n",
      "('medicine', 29.86)\n",
      "('distant', 29.86)\n",
      "('thane', 29.84)\n",
      "('nmims', 29.84)\n",
      "('site', 29.84)\n",
      "('et', 29.84)\n",
      "('machine', 29.84)\n",
      "('cousera', 29.84)\n",
      "('birla', 29.83)\n",
      "('trivandrum', 29.83)\n",
      "('blogs', 29.83)\n",
      "('processing', 29.83)\n",
      "('scipy', 29.83)\n",
      "('numpy', 29.83)\n",
      "('mind', 29.82)\n",
      "('learnbay', 29.81)\n",
      "('gratuite', 29.79)\n",
      "('vourse', 29.78)\n",
      "('sla', 29.78)\n",
      "('datafalir', 29.78)\n",
      "('outils', 29.78)\n",
      "('máster', 29.78)\n",
      "('amado', 29.78)\n",
      "('cortez', 29.78)\n",
      "('rita', 29.78)\n",
      "('s', 29.78)\n",
      "('moro', 29.78)\n",
      "('research', 29.78)\n",
      "('trends', 29.78)\n",
      "('modeling', 29.78)\n",
      "('based', 29.78)\n",
      "('literature', 29.78)\n",
      "('base', 29.78)\n",
      "('du', 29.78)\n",
      "('100', 29.77)\n",
      "('placements', 29.77)\n",
      "('киевстар', 29.77)\n",
      "('coding', 29.76)\n",
      "('cca175', 29.75)\n",
      "('edulab', 29.73)\n",
      "('who', 29.7)\n",
      "('technogeeks', 29.67)\n",
      "('rg', 29.6)\n",
      "('remoteexception', 29.6)\n",
      "('standbyexception', 29.6)\n",
      "('tamilnadu', 29.59)\n",
      "('coarse', 29.58)\n",
      "('mit', 29.5)\n",
      "('open', 29.5)\n",
      "('zaloni', 29.45)\n",
      "('bi', 29.42)\n",
      "('startups', 29.42)\n",
      "('javatpoint', 29.4)\n",
      "('attempt', 29.37)\n",
      "('menu', 29.37)\n",
      "('teste', 29.37)\n",
      "('congitive', 29.36)\n",
      "('catalog', 29.35)\n",
      "('tech', 29.3)\n",
      "('comp', 29.3)\n",
      "('sc', 29.3)\n",
      "('bigdatacoursespro', 29.28)\n",
      "('beginner', 29.26)\n",
      "('advance', 29.26)\n",
      "('credentials', 29.25)\n",
      "('español', 29.24)\n",
      "('taming', 29.2)\n",
      "('kya', 29.17)\n",
      "('chahie', 29.17)\n",
      "('cognativeclasses', 29.12)\n",
      "('cipet', 29.04)\n",
      "('month', 29.04)\n",
      "('étude', 29.03)\n",
      "('cas', 29.03)\n",
      "('exemple', 29.03)\n",
      "('noida', 29.01)\n",
      "('human', 29.01)\n",
      "('face', 29.01)\n",
      "('latino', 29.01)\n",
      "('life', 28.99)\n",
      "('unccelearn', 28.96)\n",
      "('confirm', 28.96)\n",
      "('php', 28.96)\n",
      "('ib1qa2ealednjpp', 28.96)\n",
      "('massalbaye', 28.96)\n",
      "('geoinsyssoft', 28.96)\n",
      "('per', 28.93)\n",
      "('bharti', 28.93)\n",
      "('name', 28.9)\n",
      "('one', 28.9)\n",
      "('drivers', 28.9)\n",
      "('teachers', 28.87)\n",
      "('their', 28.8)\n",
      "('rands', 28.8)\n",
      "('yraining', 28.64)\n",
      "('am', 28.57)\n",
      "('backgroud', 28.57)\n",
      "('willing', 28.57)\n",
      "('uppal', 28.36)\n",
      "('steps', 28.26)\n",
      "('django', 28.21)\n",
      "('blog', 28.16)\n",
      "('nlp', 28.15)\n",
      "('task', 28.15)\n",
      "('artificial', 28.15)\n",
      "('intelligence', 28.15)\n",
      "('tutorials', 28.02)\n",
      "('kr', 27.92)\n",
      "('puram', 27.92)\n",
      "('techetraining', 27.86)\n",
      "('mongo', 27.83)\n",
      "('db', 27.83)\n",
      "('analist', 27.49)\n",
      "('analytixlabs', 27.32)\n",
      "('eureka', 27.04)\n",
      "('linux', 26.99)\n",
      "('degree', 26.83)\n",
      "('important', 26.83)\n",
      "('module', 26.73)\n",
      "('nit', 26.43)\n",
      "('rourkela', 26.43)\n",
      "('weeks', 26.24)\n",
      "('kafka', 26.24)\n",
      "('may', 26.24)\n",
      "('13', 26.24)\n",
      "('21', 26.24)\n",
      "('itversity', 26.22)\n",
      "('new', 25.91)\n",
      "('zealand', 25.91)\n",
      "('duration', 25.91)\n",
      "('trendytech', 25.89)\n",
      "('australia', 25.83)\n",
      "('helper', 25.76)\n",
      "('intership', 25.58)\n",
      "('hydrabad', 25.58)\n",
      "('cdac', 25.58)\n",
      "('linkedin', 25.58)\n",
      "('faculty', 25.4)\n",
      "('banglore', 25.21)\n",
      "('sciens', 25.0)\n",
      "('topics', 25.0)\n",
      "('websie', 24.99)\n",
      "('cheat', 24.98)\n",
      "('sheet', 24.98)\n",
      "('intellepat', 24.98)\n",
      "('soft', 24.96)\n",
      "('post', 24.96)\n",
      "('graduate', 24.96)\n",
      "('karachi', 24.96)\n",
      "('vtu', 24.95)\n",
      "('presto', 24.95)\n",
      "('trining', 24.95)\n",
      "('excelr', 24.92)\n",
      "('we', 24.92)\n",
      "('start', 24.92)\n",
      "('banking', 24.9)\n",
      "('finance', 24.9)\n",
      "('analytical', 24.9)\n",
      "('nsdc', 24.9)\n",
      "('azure', 24.9)\n",
      "('largest', 24.87)\n",
      "('players', 24.87)\n",
      "('material', 24.87)\n",
      "('emcdsa', 24.85)\n",
      "('utilized', 24.85)\n",
      "('action', 24.85)\n",
      "('today', 24.85)\n",
      "('1000', 24.84)\n",
      "('dollars', 24.84)\n",
      "('quora', 24.84)\n",
      "('calculator', 24.83)\n",
      "('prerequisites', 24.83)\n",
      "('scd', 24.82)\n",
      "('stack', 24.77)\n",
      "('freshers', 24.76)\n",
      "('offer', 24.75)\n",
      "('centers', 24.74)\n",
      "('madhapur', 24.74)\n",
      "('mitx', 24.72)\n",
      "('development', 24.71)\n",
      "('cource', 24.71)\n",
      "('bid', 24.7)\n",
      "('1ywar', 24.7)\n",
      "('south', 24.7)\n",
      "('bootcamp', 24.69)\n",
      "('classification', 24.69)\n",
      "('subjects', 24.68)\n",
      "('paras', 24.67)\n",
      "('provision', 24.67)\n",
      "('skills', 24.67)\n",
      "('starter', 24.67)\n",
      "('kit', 24.67)\n",
      "('ecosystems', 24.66)\n",
      "('contentsbto', 24.66)\n",
      "('hacking', 24.66)\n",
      "('hortonworks', 24.65)\n",
      "('multiple', 24.63)\n",
      "('choice', 24.63)\n",
      "('quesy', 24.63)\n",
      "('solutions', 24.61)\n",
      "('storage', 24.6)\n",
      "('sessions', 24.6)\n",
      "('upgrad', 24.57)\n",
      "('bombay', 24.55)\n",
      "('anyaless', 24.54)\n",
      "('kolhapur', 24.54)\n",
      "('feedback', 24.54)\n",
      "('attending', 24.54)\n",
      "('workshop', 24.54)\n",
      "('part', 24.51)\n",
      "(\"v's\", 24.51)\n",
      "('bigdatauniversity', 24.48)\n",
      "('partner', 24.45)\n",
      "('kundalahalli', 24.43)\n",
      "('table', 24.43)\n",
      "('supporting', 24.39)\n",
      "('scalability', 24.39)\n",
      "('true', 24.39)\n",
      "('or', 24.39)\n",
      "('false', 24.39)\n",
      "('sathish', 24.39)\n",
      "('yellanki', 24.39)\n",
      "('ata', 24.38)\n",
      "('ayllabus', 24.38)\n",
      "('sqoop', 24.36)\n",
      "('jnu', 24.31)\n",
      "('intelipat', 24.25)\n",
      "('want', 24.21)\n",
      "('lecture', 24.21)\n",
      "('impala', 24.17)\n",
      "('contents', 24.06)\n",
      "('greatlearning', 24.05)\n",
      "('necessary', 23.99)\n",
      "('similar', 23.99)\n",
      "('driver', 23.91)\n",
      "('banks', 23.91)\n",
      "('continuous', 23.91)\n",
      "('be', 23.91)\n",
      "('education', 23.9)\n",
      "('web', 23.89)\n",
      "('mca', 23.89)\n",
      "('computer', 23.88)\n",
      "('report', 23.86)\n",
      "('updates', 23.63)\n",
      "('scientost', 23.61)\n",
      "('congnitive', 23.58)\n",
      "('draw', 23.57)\n",
      "('framework', 23.57)\n",
      "('analytic', 23.57)\n",
      "('year', 23.38)\n",
      "('question', 23.38)\n",
      "('c++', 23.34)\n",
      "('hands', 23.3)\n",
      "('mapr', 23.25)\n",
      "('dat', 23.22)\n",
      "('costs', 23.09)\n",
      "('assignments', 23.0)\n",
      "('gcp', 22.96)\n",
      "('trainjng', 22.96)\n",
      "('acknowledge', 22.83)\n",
      "('firms', 22.83)\n",
      "('ciencia', 22.79)\n",
      "('datos', 22.79)\n",
      "('tirupati', 22.74)\n",
      "('has', 22.73)\n",
      "('value', 22.73)\n",
      "('kharadi', 22.71)\n",
      "('polytechnic', 22.69)\n",
      "('just', 22.4)\n",
      "('below', 22.4)\n",
      "('amity', 22.35)\n",
      "('answer', 22.35)\n",
      "('cv', 22.19)\n",
      "('cse', 22.19)\n",
      "('student', 22.19)\n",
      "('visualizing', 22.12)\n",
      "('m', 21.9)\n",
      "('conduct', 21.9)\n",
      "('trending', 21.78)\n",
      "('classroom', 21.44)\n",
      "('intellepaat', 21.33)\n",
      "('seema', 21.32)\n",
      "('acharya', 21.32)\n",
      "('subhashini', 21.32)\n",
      "('chellappan', 21.32)\n",
      "('infosys', 21.32)\n",
      "('publication', 21.32)\n",
      "('wiley', 21.32)\n",
      "('private', 21.32)\n",
      "('1st', 21.32)\n",
      "('edition', 21.32)\n",
      "('laptop', 21.3)\n",
      "('keyskills', 20.87)\n",
      "('ofhadoop', 20.87)\n",
      "('adminstartor', 20.87)\n",
      "('date', 20.65)\n",
      "('vidya', 20.65)\n",
      "('learnathone', 20.65)\n",
      "('denotes', 20.64)\n",
      "('several', 20.64)\n",
      "('kinds', 20.64)\n",
      "('that', 20.64)\n",
      "('changes', 20.64)\n",
      "('ina', 20.64)\n",
      "('rapid', 20.64)\n",
      "('hdpcd', 20.6)\n",
      "('*', 20.0)\n",
      "('loading', 20.0)\n",
      "('oracle', 20.0)\n",
      "('2.4', 20.0)\n",
      "('zimbabwe', 20.0)\n",
      "('penerapan', 20.0)\n",
      "('pada', 20.0)\n",
      "('media', 20.0)\n",
      "('analytcs', 20.0)\n",
      "('summmer', 20.0)\n",
      "('rdd', 19.98)\n",
      "('sum', 19.98)\n",
      "('used', 19.97)\n",
      "('applications', 19.89)\n",
      "('sujets', 19.84)\n",
      "('mémoire', 19.84)\n",
      "('orienté', 19.84)\n",
      "('analyse', 19.84)\n",
      "('cassandra', 19.81)\n",
      "('show', 19.8)\n",
      "('dataset', 19.79)\n",
      "('dataframe', 19.64)\n",
      "('minutes', 19.46)\n",
      "('speech', 19.46)\n",
      "('english', 19.46)\n",
      "('groups', 19.4)\n",
      "('understanding', 19.34)\n",
      "('hue', 19.21)\n",
      "('lower', 19.19)\n",
      "('testers', 19.18)\n",
      "('github', 19.16)\n",
      "('entrycomputer', 18.85)\n",
      "('rajouri', 18.85)\n",
      "('garden', 18.85)\n",
      "('community', 18.84)\n",
      "('marathahalli', 18.77)\n",
      "('concepts', 18.72)\n",
      "('qualification', 18.38)\n",
      "('haarop', 18.38)\n",
      "('leanr', 17.9)\n",
      "('store', 17.38)\n",
      "('very', 17.38)\n",
      "('amounts', 17.38)\n",
      "('weekend', 17.03)\n",
      "('motivation', 16.78)\n",
      "('behind', 16.78)\n",
      "('discount', 16.68)\n",
      "('algorithm', 16.44)\n",
      "('scienctist', 16.41)\n",
      "('indore', 16.41)\n",
      "('any', 15.16)\n",
      "('helping', 15.16)\n",
      "('physics', 15.12)\n",
      "('тема', 15.0)\n",
      "('за', 15.0)\n",
      "('pelatihan', 15.0)\n",
      "('basses', 15.0)\n",
      "('term', 15.0)\n",
      "('funding', 15.0)\n",
      "('prerequisite', 15.0)\n",
      "('pdg', 12.49)\n",
      "('div', 12.22)\n",
      "('li', 12.22)\n",
      "('profile', 12.22)\n",
      "('badge', 12.22)\n",
      "('version', 12.22)\n",
      "('v1', 12.22)\n",
      "('size', 12.22)\n",
      "('medium', 12.22)\n",
      "('locale', 12.22)\n",
      "('fr_fr', 12.22)\n",
      "('type', 12.22)\n",
      "('theme', 12.22)\n",
      "('vanity', 12.22)\n",
      "('total', 12.21)\n",
      "('gemology', 10.37)\n",
      "('cochig', 10.0)\n",
      "('jogja', 10.0)\n",
      "('binus', 9.87)\n",
      "('alam', 9.87)\n",
      "('suter', 9.87)\n",
      "('oder', 9.18)\n",
      "('mumbai', 8.88)\n",
      "('ar', 2.16)\n",
      "('le', 0.85)\n",
      "('60', 0.85)\n",
      "('secondes', 0.85)\n",
      "('pour', 0.85)\n",
      "('comprendre', 0.85)\n",
      "('sumit', 0.58)\n",
      "('installer', 0.31)\n",
      "('sur', 0.31)\n",
      "('windows', 0.31)\n",
      "('scoop', 0.29)\n",
      "('map', 0.19)\n",
      "('reduce', 0.19)\n",
      "('technique', 0.19)\n",
      "('disease', 0.17)\n",
      "('diagnosis', 0.17)\n",
      "('stock', 0.12)\n",
      "('concept', 0.05)\n",
      "('making', 0.01)\n",
      "('scatter', 0.01)\n",
      "('chart', 0.01)\n",
      "('excel', 0.01)\n"
     ]
    }
   ],
   "source": [
    "for i in ans:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c5d392d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "834"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40634466",
   "metadata": {},
   "source": [
    "# BRODCASTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebed1e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadBoringWords():\n",
    "    boring_words = set(line.strip() for line in open(\"boring.txt\"))\n",
    "    return boring_words\n",
    "name_set = sc.broadcast(loadBoringWords())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cdcf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_rdd1 = sc.textFile(\"bigdatacampaigndata-201014-183159.csv\")\n",
    "mapped_input = initial_rdd1.map(lambda x: (float(x.split(\",\")[10]),x.split(\",\")[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfc37a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('hadoop', 4818.339999999999)\n",
      "('intellipaat', 2081.2200000000003)\n",
      "('analytics', 1458.5100000000004)\n",
      "('hyderabad', 1118.16)\n",
      "('spark', 1078.72)\n",
      "('bangalore', 1039.27)\n",
      "('cloudxlab', 707.52)\n",
      "('bigdata', 694.4800000000001)\n",
      "('dataflair', 643.9)\n",
      "('chennai', 604.0400000000001)\n",
      "('edureka', 351.44)\n",
      "('iit', 308.72999999999996)\n",
      "('coursera', 293.25)\n",
      "('pune', 284.71)\n",
      "('curso', 277.53000000000003)\n",
      "('cloudera', 258.06)\n",
      "('simplilearn', 252.45)\n",
      "('scala', 250.73)\n",
      "('ameerpet', 184.94000000000003)\n",
      "('flair', 154.13)\n"
     ]
    }
   ],
   "source": [
    "words = mapped_input.flatMapValues(lambda x: x.split(\" \"))\n",
    "final_mapped = words.map(lambda x: (x[1].lower(),x[0]))\n",
    "filtered_rdd = final_mapped.filter(lambda x: x[0] not in name_set.value)\n",
    "total = filtered_rdd.reduceByKey(lambda x,y: x+y)\n",
    "sorted = total.sortBy(lambda x: x[1],False)\n",
    "result = sorted.take(20)\n",
    "for x in result:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297707ba",
   "metadata": {},
   "source": [
    "# ACCUMULATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c041ab05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blankLineChecker(line):\n",
    "    if len(line)==0:\n",
    "        myaccum.add(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c89398b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "myrdd = sc.textFile(\"samplefile.txt\")\n",
    "myaccum = sc.accumulator(0)\n",
    "myrdd.foreach(blankLineChecker)\n",
    "print(myaccum.value)\n",
    "\n",
    "#Note- We can use foreach on a rdd but not on a local variable \n",
    "#example \n",
    "#lista = rdd.collect======\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec9e087",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddd965e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db6273e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = [\"WARN: Tuesday 4 September 0405\",\n",
    "           \"ERROR: Tuesday 4 September 0408\",\n",
    "           \"ERROR: Tuesday 4 September 0408\",\n",
    "           \"ERROR: Tuesday 4 September 0408\",\n",
    "           \"ERROR: Tuesday 4 September 0408\",\n",
    "           \"ERROR: Tuesday 4 September 0408\"]\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05d3f32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=sc.parallelize(my_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a96e0cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=a.map(lambda x:(x.split(':')[0],1))\n",
    "ans=k.reduceByKey(lambda x,y:x+y)\n",
    "res=ans.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e28bf248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('WARN', 1)\n",
      "('ERROR', 5)\n"
     ]
    }
   ],
   "source": [
    "for i in res:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6836eeb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bd83725",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('WARN', 1)\n",
      "('ERROR', 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    my_list = [\"WARN: Tuesday 4 September 0405\",\n",
    "               \"ERROR: Tuesday 4 September 0408\",\n",
    "               \"ERROR: Tuesday 4 September 0408\",\n",
    "               \"ERROR: Tuesday 4 September 0408\",\n",
    "               \"ERROR: Tuesday 4 September 0408\",\n",
    "               \"ERROR: Tuesday 4 September 0408\"]\n",
    "    original_logs_rdd = sc.parallelize(my_list)\n",
    "else:\n",
    "    original_logs_rdd = sc.textFile(\"logsample.txt\")\n",
    "    print(\"inside the else part\")\n",
    "new_pair_rdd = original_logs_rdd.map(lambda x:(x.split(\":\")[0],1))\n",
    "resultant_rdd = new_pair_rdd.reduceByKey(lambda x,y: x+y)\n",
    "result = resultant_rdd.collect()\n",
    "for x in result:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421edaf6",
   "metadata": {},
   "source": [
    "# EXAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42b255a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/26 18:13:12 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 221.4 KiB, free 434.2 MiB)\n",
      "22/10/26 18:13:12 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.5 KiB, free 434.2 MiB)\n",
      "22/10/26 18:13:12 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.29.199:50379 (size: 32.5 KiB, free: 434.4 MiB)\n",
      "22/10/26 18:13:12 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:0\n",
      "22/10/26 18:13:12 INFO FileInputFormat: Total input files to process : 1\n",
      "22/10/26 18:13:12 INFO SparkContext: Starting job: collect at /var/folders/7r/x4_8ch8j5w547gls5xdcg2_40000gn/T/ipykernel_44346/3536254349.py:6\n",
      "22/10/26 18:13:12 INFO DAGScheduler: Registering RDD 3 (groupByKey at /var/folders/7r/x4_8ch8j5w547gls5xdcg2_40000gn/T/ipykernel_44346/3536254349.py:4) as input to shuffle 0\n",
      "22/10/26 18:13:12 INFO DAGScheduler: Got job 0 (collect at /var/folders/7r/x4_8ch8j5w547gls5xdcg2_40000gn/T/ipykernel_44346/3536254349.py:6) with 11 output partitions\n",
      "22/10/26 18:13:12 INFO DAGScheduler: Final stage: ResultStage 1 (collect at /var/folders/7r/x4_8ch8j5w547gls5xdcg2_40000gn/T/ipykernel_44346/3536254349.py:6)\n",
      "22/10/26 18:13:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)\n",
      "22/10/26 18:13:12 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)\n",
      "22/10/26 18:13:12 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[3] at groupByKey at /var/folders/7r/x4_8ch8j5w547gls5xdcg2_40000gn/T/ipykernel_44346/3536254349.py:4), which has no missing parents\n",
      "22/10/26 18:13:12 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 12.5 KiB, free 434.1 MiB)\n",
      "22/10/26 18:13:12 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.5 KiB, free 434.1 MiB)\n",
      "22/10/26 18:13:12 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.29.199:50379 (size: 7.5 KiB, free: 434.4 MiB)\n",
      "22/10/26 18:13:12 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1513\n",
      "22/10/26 18:13:12 INFO DAGScheduler: Submitting 11 missing tasks from ShuffleMapStage 0 (PairwiseRDD[3] at groupByKey at /var/folders/7r/x4_8ch8j5w547gls5xdcg2_40000gn/T/ipykernel_44346/3536254349.py:4) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10))\n",
      "22/10/26 18:13:12 INFO TaskSchedulerImpl: Adding task set 0.0 with 11 tasks resource profile 0\n",
      "22/10/26 18:13:12 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (192.168.29.199, executor driver, partition 0, PROCESS_LOCAL, 4503 bytes) taskResourceAssignments Map()\n",
      "22/10/26 18:13:12 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)\n",
      "22/10/26 18:13:12 INFO HadoopRDD: Input split: file:/Users/ashwinpandey/Downloads/bigLog.txt:0+33554432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                         (0 + 1) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/26 18:13:15 INFO PythonRunner: Times: total = 2424, boot = 799, init = 9, finish = 1616\n",
      "22/10/26 18:13:15 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1631 bytes result sent to driver\n",
      "22/10/26 18:13:15 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1) (192.168.29.199, executor driver, partition 1, PROCESS_LOCAL, 4503 bytes) taskResourceAssignments Map()\n",
      "22/10/26 18:13:15 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)\n",
      "22/10/26 18:13:15 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2530 ms on 192.168.29.199 (executor driver) (1/11)\n",
      "22/10/26 18:13:15 INFO HadoopRDD: Input split: file:/Users/ashwinpandey/Downloads/bigLog.txt:33554432+33554432\n",
      "22/10/26 18:13:15 INFO PythonAccumulatorV2: Connected to AccumulatorServer at host: 127.0.0.1 port: 50380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:=====>                                                    (1 + 1) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/26 18:13:16 INFO PythonRunner: Times: total = 1464, boot = -39, init = 43, finish = 1460\n",
      "22/10/26 18:13:16 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1631 bytes result sent to driver\n",
      "22/10/26 18:13:16 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2) (192.168.29.199, executor driver, partition 2, PROCESS_LOCAL, 4503 bytes) taskResourceAssignments Map()\n",
      "22/10/26 18:13:16 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)\n",
      "22/10/26 18:13:16 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 1499 ms on 192.168.29.199 (executor driver) (2/11)\n",
      "22/10/26 18:13:16 INFO HadoopRDD: Input split: file:/Users/ashwinpandey/Downloads/bigLog.txt:67108864+33554432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:==========>                                               (2 + 1) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/26 18:13:18 INFO PythonRunner: Times: total = 1453, boot = -25, init = 26, finish = 1452\n",
      "22/10/26 18:13:18 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1631 bytes result sent to driver\n",
      "22/10/26 18:13:18 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3) (192.168.29.199, executor driver, partition 3, PROCESS_LOCAL, 4503 bytes) taskResourceAssignments Map()\n",
      "22/10/26 18:13:18 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 1478 ms on 192.168.29.199 (executor driver) (3/11)\n",
      "22/10/26 18:13:18 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)\n",
      "22/10/26 18:13:18 INFO HadoopRDD: Input split: file:/Users/ashwinpandey/Downloads/bigLog.txt:100663296+33554432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:===============>                                          (3 + 1) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/26 18:13:19 INFO PythonRunner: Times: total = 1460, boot = -20, init = 21, finish = 1459\n",
      "22/10/26 18:13:19 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1631 bytes result sent to driver\n",
      "22/10/26 18:13:19 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4) (192.168.29.199, executor driver, partition 4, PROCESS_LOCAL, 4503 bytes) taskResourceAssignments Map()\n",
      "22/10/26 18:13:19 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 1482 ms on 192.168.29.199 (executor driver) (4/11)\n",
      "22/10/26 18:13:19 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)\n",
      "22/10/26 18:13:19 INFO HadoopRDD: Input split: file:/Users/ashwinpandey/Downloads/bigLog.txt:134217728+33554432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:=====================>                                    (4 + 1) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/26 18:13:21 INFO PythonRunner: Times: total = 1475, boot = -16, init = 17, finish = 1474\n",
      "22/10/26 18:13:21 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1631 bytes result sent to driver\n",
      "22/10/26 18:13:21 INFO TaskSetManager: Starting task 5.0 in stage 0.0 (TID 5) (192.168.29.199, executor driver, partition 5, PROCESS_LOCAL, 4503 bytes) taskResourceAssignments Map()\n",
      "22/10/26 18:13:21 INFO Executor: Running task 5.0 in stage 0.0 (TID 5)\n",
      "22/10/26 18:13:21 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 1499 ms on 192.168.29.199 (executor driver) (5/11)\n",
      "22/10/26 18:13:21 INFO HadoopRDD: Input split: file:/Users/ashwinpandey/Downloads/bigLog.txt:167772160+33554432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:==========================>                               (5 + 1) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/26 18:13:22 INFO PythonRunner: Times: total = 1476, boot = -17, init = 18, finish = 1475\n",
      "22/10/26 18:13:22 INFO Executor: Finished task 5.0 in stage 0.0 (TID 5). 1631 bytes result sent to driver\n",
      "22/10/26 18:13:22 INFO TaskSetManager: Starting task 6.0 in stage 0.0 (TID 6) (192.168.29.199, executor driver, partition 6, PROCESS_LOCAL, 4503 bytes) taskResourceAssignments Map()\n",
      "22/10/26 18:13:22 INFO Executor: Running task 6.0 in stage 0.0 (TID 6)\n",
      "22/10/26 18:13:22 INFO TaskSetManager: Finished task 5.0 in stage 0.0 (TID 5) in 1500 ms on 192.168.29.199 (executor driver) (6/11)\n",
      "22/10/26 18:13:22 INFO HadoopRDD: Input split: file:/Users/ashwinpandey/Downloads/bigLog.txt:201326592+33554432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:===============================>                          (6 + 1) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/26 18:13:24 INFO PythonRunner: Times: total = 1457, boot = -19, init = 20, finish = 1456\n",
      "22/10/26 18:13:24 INFO Executor: Finished task 6.0 in stage 0.0 (TID 6). 1631 bytes result sent to driver\n",
      "22/10/26 18:13:24 INFO TaskSetManager: Starting task 7.0 in stage 0.0 (TID 7) (192.168.29.199, executor driver, partition 7, PROCESS_LOCAL, 4503 bytes) taskResourceAssignments Map()\n",
      "22/10/26 18:13:24 INFO TaskSetManager: Finished task 6.0 in stage 0.0 (TID 6) in 1481 ms on 192.168.29.199 (executor driver) (7/11)\n",
      "22/10/26 18:13:24 INFO Executor: Running task 7.0 in stage 0.0 (TID 7)\n",
      "22/10/26 18:13:24 INFO HadoopRDD: Input split: file:/Users/ashwinpandey/Downloads/bigLog.txt:234881024+33554432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:====================================>                     (7 + 1) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/26 18:13:25 INFO PythonRunner: Times: total = 1456, boot = -19, init = 20, finish = 1455\n",
      "22/10/26 18:13:25 INFO Executor: Finished task 7.0 in stage 0.0 (TID 7). 1631 bytes result sent to driver\n",
      "22/10/26 18:13:25 INFO TaskSetManager: Starting task 8.0 in stage 0.0 (TID 8) (192.168.29.199, executor driver, partition 8, PROCESS_LOCAL, 4503 bytes) taskResourceAssignments Map()\n",
      "22/10/26 18:13:25 INFO TaskSetManager: Finished task 7.0 in stage 0.0 (TID 7) in 1480 ms on 192.168.29.199 (executor driver) (8/11)\n",
      "22/10/26 18:13:25 INFO Executor: Running task 8.0 in stage 0.0 (TID 8)\n",
      "22/10/26 18:13:25 INFO HadoopRDD: Input split: file:/Users/ashwinpandey/Downloads/bigLog.txt:268435456+33554432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:==========================================>               (8 + 1) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/26 18:13:27 INFO PythonRunner: Times: total = 1475, boot = -17, init = 18, finish = 1474\n",
      "22/10/26 18:13:27 INFO Executor: Finished task 8.0 in stage 0.0 (TID 8). 1588 bytes result sent to driver\n",
      "22/10/26 18:13:27 INFO TaskSetManager: Starting task 9.0 in stage 0.0 (TID 9) (192.168.29.199, executor driver, partition 9, PROCESS_LOCAL, 4503 bytes) taskResourceAssignments Map()\n",
      "22/10/26 18:13:27 INFO Executor: Running task 9.0 in stage 0.0 (TID 9)\n",
      "22/10/26 18:13:27 INFO TaskSetManager: Finished task 8.0 in stage 0.0 (TID 8) in 1498 ms on 192.168.29.199 (executor driver) (9/11)\n",
      "22/10/26 18:13:27 INFO HadoopRDD: Input split: file:/Users/ashwinpandey/Downloads/bigLog.txt:301989888+33554432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:===============================================>          (9 + 1) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/26 18:13:28 INFO PythonRunner: Times: total = 1455, boot = -18, init = 19, finish = 1454\n",
      "22/10/26 18:13:28 INFO Executor: Finished task 9.0 in stage 0.0 (TID 9). 1588 bytes result sent to driver\n",
      "22/10/26 18:13:28 INFO TaskSetManager: Starting task 10.0 in stage 0.0 (TID 10) (192.168.29.199, executor driver, partition 10, PROCESS_LOCAL, 4503 bytes) taskResourceAssignments Map()\n",
      "22/10/26 18:13:28 INFO TaskSetManager: Finished task 9.0 in stage 0.0 (TID 9) in 1482 ms on 192.168.29.199 (executor driver) (10/11)\n",
      "22/10/26 18:13:28 INFO Executor: Running task 10.0 in stage 0.0 (TID 10)\n",
      "22/10/26 18:13:28 INFO HadoopRDD: Input split: file:/Users/ashwinpandey/Downloads/bigLog.txt:335544320+29456794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:===================================================>     (10 + 1) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/26 18:13:29 INFO PythonRunner: Times: total = 1272, boot = -22, init = 23, finish = 1271\n",
      "22/10/26 18:13:29 INFO Executor: Finished task 10.0 in stage 0.0 (TID 10). 1588 bytes result sent to driver\n",
      "22/10/26 18:13:29 INFO TaskSetManager: Finished task 10.0 in stage 0.0 (TID 10) in 1294 ms on 192.168.29.199 (executor driver) (11/11)\n",
      "22/10/26 18:13:29 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool \n",
      "22/10/26 18:13:29 INFO DAGScheduler: ShuffleMapStage 0 (groupByKey at /var/folders/7r/x4_8ch8j5w547gls5xdcg2_40000gn/T/ipykernel_44346/3536254349.py:4) finished in 17.254 s\n",
      "22/10/26 18:13:29 INFO DAGScheduler: looking for newly runnable stages\n",
      "22/10/26 18:13:29 INFO DAGScheduler: running: Set()\n",
      "22/10/26 18:13:29 INFO DAGScheduler: waiting: Set(ResultStage 1)\n",
      "22/10/26 18:13:29 INFO DAGScheduler: failed: Set()\n",
      "22/10/26 18:13:29 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[6] at collect at /var/folders/7r/x4_8ch8j5w547gls5xdcg2_40000gn/T/ipykernel_44346/3536254349.py:6), which has no missing parents\n",
      "22/10/26 18:13:29 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 11.3 KiB, free 434.1 MiB)\n",
      "22/10/26 18:13:29 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 434.1 MiB)\n",
      "22/10/26 18:13:29 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.29.199:50379 (size: 6.4 KiB, free: 434.4 MiB)\n",
      "22/10/26 18:13:29 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1513\n",
      "22/10/26 18:13:29 INFO DAGScheduler: Submitting 11 missing tasks from ResultStage 1 (PythonRDD[6] at collect at /var/folders/7r/x4_8ch8j5w547gls5xdcg2_40000gn/T/ipykernel_44346/3536254349.py:6) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10))\n",
      "22/10/26 18:13:29 INFO TaskSchedulerImpl: Adding task set 1.0 with 11 tasks resource profile 0\n",
      "22/10/26 18:13:29 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 11) (192.168.29.199, executor driver, partition 2, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "22/10/26 18:13:29 INFO Executor: Running task 2.0 in stage 1.0 (TID 11)\n",
      "22/10/26 18:13:29 INFO ShuffleBlockFetcherIterator: Getting 11 (39.7 MiB) non-empty blocks including 11 (39.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "22/10/26 18:13:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms\n",
      "22/10/26 18:13:30 INFO PythonRunner: Times: total = 455, boot = -55, init = 70, finish = 440\n",
      "22/10/26 18:13:30 INFO Executor: Finished task 2.0 in stage 1.0 (TID 11). 1675 bytes result sent to driver\n",
      "22/10/26 18:13:30 INFO TaskSetManager: Starting task 6.0 in stage 1.0 (TID 12) (192.168.29.199, executor driver, partition 6, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "22/10/26 18:13:30 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 11) in 484 ms on 192.168.29.199 (executor driver) (1/11)\n",
      "22/10/26 18:13:30 INFO Executor: Running task 6.0 in stage 1.0 (TID 12)\n",
      "22/10/26 18:13:30 INFO ShuffleBlockFetcherIterator: Getting 11 (39.7 MiB) non-empty blocks including 11 (39.7 MiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "22/10/26 18:13:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 1:=====>                                                    (1 + 1) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/26 18:13:32 INFO PythonRunner: Times: total = 2125, boot = 0, init = 8, finish = 2117\n",
      "22/10/26 18:13:32 INFO Executor: Finished task 6.0 in stage 1.0 (TID 12). 1633 bytes result sent to driver\n",
      "22/10/26 18:13:32 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 13) (192.168.29.199, executor driver, partition 0, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "22/10/26 18:13:32 INFO TaskSetManager: Finished task 6.0 in stage 1.0 (TID 12) in 2133 ms on 192.168.29.199 (executor driver) (2/11)\n",
      "22/10/26 18:13:32 INFO Executor: Running task 0.0 in stage 1.0 (TID 13)\n",
      "22/10/26 18:13:32 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "22/10/26 18:13:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "22/10/26 18:13:32 INFO PythonRunner: Times: total = 10, boot = -1, init = 2, finish = 9\n",
      "22/10/26 18:13:32 INFO Executor: Finished task 0.0 in stage 1.0 (TID 13). 1580 bytes result sent to driver\n",
      "22/10/26 18:13:32 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 14) (192.168.29.199, executor driver, partition 1, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "22/10/26 18:13:32 INFO Executor: Running task 1.0 in stage 1.0 (TID 14)\n",
      "22/10/26 18:13:32 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 13) in 16 ms on 192.168.29.199 (executor driver) (3/11)\n",
      "22/10/26 18:13:32 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "22/10/26 18:13:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "22/10/26 18:13:32 INFO PythonRunner: Times: total = 10, boot = -1, init = 1, finish = 10\n",
      "22/10/26 18:13:32 INFO Executor: Finished task 1.0 in stage 1.0 (TID 14). 1537 bytes result sent to driver\n",
      "22/10/26 18:13:32 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 15) (192.168.29.199, executor driver, partition 3, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "22/10/26 18:13:32 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 14) in 15 ms on 192.168.29.199 (executor driver) (4/11)\n",
      "22/10/26 18:13:32 INFO Executor: Running task 3.0 in stage 1.0 (TID 15)\n",
      "22/10/26 18:13:32 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "22/10/26 18:13:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "22/10/26 18:13:32 INFO PythonRunner: Times: total = 10, boot = -1, init = 1, finish = 10\n",
      "22/10/26 18:13:32 INFO Executor: Finished task 3.0 in stage 1.0 (TID 15). 1580 bytes result sent to driver\n",
      "22/10/26 18:13:32 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 16) (192.168.29.199, executor driver, partition 4, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "22/10/26 18:13:32 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 15) in 17 ms on 192.168.29.199 (executor driver) (5/11)\n",
      "22/10/26 18:13:32 INFO Executor: Running task 4.0 in stage 1.0 (TID 16)\n",
      "22/10/26 18:13:32 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "22/10/26 18:13:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "22/10/26 18:13:32 INFO PythonRunner: Times: total = 9, boot = -1, init = 1, finish = 9\n",
      "22/10/26 18:13:32 INFO Executor: Finished task 4.0 in stage 1.0 (TID 16). 1537 bytes result sent to driver\n",
      "22/10/26 18:13:32 INFO TaskSetManager: Starting task 5.0 in stage 1.0 (TID 17) (192.168.29.199, executor driver, partition 5, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "22/10/26 18:13:32 INFO Executor: Running task 5.0 in stage 1.0 (TID 17)\n",
      "22/10/26 18:13:32 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 16) in 15 ms on 192.168.29.199 (executor driver) (6/11)\n",
      "22/10/26 18:13:32 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "22/10/26 18:13:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "22/10/26 18:13:32 INFO PythonRunner: Times: total = 10, boot = 0, init = 1, finish = 9\n",
      "22/10/26 18:13:32 INFO Executor: Finished task 5.0 in stage 1.0 (TID 17). 1537 bytes result sent to driver\n",
      "22/10/26 18:13:32 INFO TaskSetManager: Starting task 7.0 in stage 1.0 (TID 18) (192.168.29.199, executor driver, partition 7, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "22/10/26 18:13:32 INFO Executor: Running task 7.0 in stage 1.0 (TID 18)\n",
      "22/10/26 18:13:32 INFO TaskSetManager: Finished task 5.0 in stage 1.0 (TID 17) in 15 ms on 192.168.29.199 (executor driver) (7/11)\n",
      "22/10/26 18:13:32 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "22/10/26 18:13:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "22/10/26 18:13:32 INFO PythonRunner: Times: total = 10, boot = 1, init = 0, finish = 9\n",
      "22/10/26 18:13:32 INFO Executor: Finished task 7.0 in stage 1.0 (TID 18). 1537 bytes result sent to driver\n",
      "22/10/26 18:13:32 INFO TaskSetManager: Starting task 8.0 in stage 1.0 (TID 19) (192.168.29.199, executor driver, partition 8, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "22/10/26 18:13:32 INFO Executor: Running task 8.0 in stage 1.0 (TID 19)\n",
      "22/10/26 18:13:32 INFO TaskSetManager: Finished task 7.0 in stage 1.0 (TID 18) in 15 ms on 192.168.29.199 (executor driver) (8/11)\n",
      "22/10/26 18:13:32 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "22/10/26 18:13:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "22/10/26 18:13:32 INFO PythonRunner: Times: total = 10, boot = 0, init = 1, finish = 9\n",
      "22/10/26 18:13:32 INFO Executor: Finished task 8.0 in stage 1.0 (TID 19). 1537 bytes result sent to driver\n",
      "22/10/26 18:13:32 INFO TaskSetManager: Starting task 9.0 in stage 1.0 (TID 20) (192.168.29.199, executor driver, partition 9, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "22/10/26 18:13:32 INFO Executor: Running task 9.0 in stage 1.0 (TID 20)\n",
      "22/10/26 18:13:32 INFO TaskSetManager: Finished task 8.0 in stage 1.0 (TID 19) in 15 ms on 192.168.29.199 (executor driver) (9/11)\n",
      "22/10/26 18:13:32 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "22/10/26 18:13:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "22/10/26 18:13:32 INFO PythonRunner: Times: total = 10, boot = 0, init = 0, finish = 10\n",
      "22/10/26 18:13:32 INFO Executor: Finished task 9.0 in stage 1.0 (TID 20). 1537 bytes result sent to driver\n",
      "22/10/26 18:13:32 INFO TaskSetManager: Starting task 10.0 in stage 1.0 (TID 21) (192.168.29.199, executor driver, partition 10, PROCESS_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "22/10/26 18:13:32 INFO Executor: Running task 10.0 in stage 1.0 (TID 21)\n",
      "22/10/26 18:13:32 INFO TaskSetManager: Finished task 9.0 in stage 1.0 (TID 20) in 15 ms on 192.168.29.199 (executor driver) (10/11)\n",
      "22/10/26 18:13:32 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "22/10/26 18:13:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "22/10/26 18:13:32 INFO PythonRunner: Times: total = 10, boot = 1, init = 0, finish = 9\n",
      "22/10/26 18:13:32 INFO Executor: Finished task 10.0 in stage 1.0 (TID 21). 1537 bytes result sent to driver\n",
      "22/10/26 18:13:32 INFO TaskSetManager: Finished task 10.0 in stage 1.0 (TID 21) in 15 ms on 192.168.29.199 (executor driver) (11/11)\n",
      "22/10/26 18:13:32 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool \n",
      "22/10/26 18:13:32 INFO DAGScheduler: ResultStage 1 (collect at /var/folders/7r/x4_8ch8j5w547gls5xdcg2_40000gn/T/ipykernel_44346/3536254349.py:6) finished in 2.759 s\n",
      "22/10/26 18:13:32 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/10/26 18:13:32 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished\n",
      "22/10/26 18:13:32 INFO DAGScheduler: Job 0 finished: collect at /var/folders/7r/x4_8ch8j5w547gls5xdcg2_40000gn/T/ipykernel_44346/3536254349.py:6, took 20.049889 s\n",
      "('WARN', 4998886)\n",
      "('ERROR', 5001114)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 1:===================================================>     (10 + 1) / 11]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sc.setLogLevel(\"INFO\")# Create a SparkContext using every core of the local machine\n",
    "base_rdd = sc.textFile(\"/Users/ashwinpandey/Downloads/bigLog.txt\")\n",
    "mapped_rdd = base_rdd.map(lambda x: (x.split(\":\")[0], x.split(\":\")[1]))\n",
    "grouped_rdd =  mapped_rdd.groupByKey()\n",
    "final_rdd = grouped_rdd.map(lambda x: (x[0], len(x[1])))\n",
    "result = final_rdd.collect()\n",
    "for x in result:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb3d4f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:===================================================>     (10 + 1) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('WARN', 4998886)\n",
      "('ERROR', 5001114)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "base_rdd = sc.textFile(\"/Users/ashwinpandey/Downloads/bigLog.txt\")\n",
    "mapped_rdd = base_rdd.map(lambda x: (x.split(\":\")[0], 1))\n",
    "reduced_rdd =  mapped_rdd.reduceByKey(lambda x,y: x+y)\n",
    "result = reduced_rdd.collect()\n",
    "for x in result:\n",
    "    print(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a66a7f",
   "metadata": {},
   "source": [
    "# Miscallaneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2dd09421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9d452a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=sc.defaultParallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dac2ae28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "baca24a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.defaultMinPartitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf0ed32c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_list = (\"WARN: Tuesday 4 September 0405\",\n",
    "           \"ERROR: Tuesday 4 September 0408\",\n",
    "           \"ERROR: Tuesday 4 September 0408\",\n",
    "           \"ERROR: Tuesday 4 September 0408\",\n",
    "           \"ERROR: Tuesday 4 September 0408\",\n",
    "           \"ERROR: Tuesday 4 September 0408\")\n",
    "original_logs_rdd = sc.parallelize(my_list)\n",
    "original_logs_rdd.getNumPartitions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "340406d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPARTITION AND COALESCE\n",
    "\n",
    "\n",
    "new=original_logs_rdd.repartition(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d74e88a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41c8b4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_colesce=new.coalesce(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3dfdbbd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_colesce.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba9db6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
